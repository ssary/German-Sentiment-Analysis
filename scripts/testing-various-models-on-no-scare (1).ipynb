{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7463814,"sourceType":"datasetVersion","datasetId":4332637}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:12:51.097216Z","iopub.execute_input":"2024-01-23T20:12:51.097517Z","iopub.status.idle":"2024-01-23T20:12:57.599696Z","shell.execute_reply.started":"2024-01-23T20:12:51.097481Z","shell.execute_reply":"2024-01-23T20:12:57.598782Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"german_sentiment_path = \"oliverguhr/german-sentiment-bert\"\nxlm_t_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:12:57.601181Z","iopub.execute_input":"2024-01-23T20:12:57.601628Z","iopub.status.idle":"2024-01-23T20:12:57.606065Z","shell.execute_reply.started":"2024-01-23T20:12:57.601600Z","shell.execute_reply":"2024-01-23T20:12:57.605113Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:12:57.607189Z","iopub.execute_input":"2024-01-23T20:12:57.607491Z","iopub.status.idle":"2024-01-23T20:12:57.617193Z","shell.execute_reply.started":"2024-01-23T20:12:57.607467Z","shell.execute_reply":"2024-01-23T20:12:57.616457Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def test_classification_report(model, test_text, test_labels):\n    model.eval()\n    predictions = []\n    real_labels = []\n    test_encodings = tokenizer(test_text, max_length=128, truncation=True, padding=True)\n    test_dataset = MyDataset(test_encodings, test_labels)\n    data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n\n            preds = torch.argmax(logits, dim=1)\n            predictions.extend(preds.cpu().numpy())\n            real_labels.extend(labels.cpu().numpy())\n    report = classification_report(real_labels, predictions, target_names=['Negative', 'Neutral', 'Positive'])\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:12:57.619673Z","iopub.execute_input":"2024-01-23T20:12:57.619984Z","iopub.status.idle":"2024-01-23T20:12:57.629130Z","shell.execute_reply.started":"2024-01-23T20:12:57.619961Z","shell.execute_reply":"2024-01-23T20:12:57.628189Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_text_noscare = open(\"/kaggle/input/germeval-no-scare/test_text.txt\", encoding='latin-1').read().rstrip('\\n').split('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:12:57.630363Z","iopub.execute_input":"2024-01-23T20:12:57.630683Z","iopub.status.idle":"2024-01-23T20:12:59.657091Z","shell.execute_reply.started":"2024-01-23T20:12:57.630653Z","shell.execute_reply":"2024-01-23T20:12:59.655705Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/germeval-no-scare/test_labels.txt\", encoding='latin-1') as file:\n    test_labels_noscare = [int(line.strip()) for line in file]","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:12:59.658632Z","iopub.execute_input":"2024-01-23T20:12:59.658960Z","iopub.status.idle":"2024-01-23T20:12:59.916217Z","shell.execute_reply.started":"2024-01-23T20:12:59.658932Z","shell.execute_reply":"2024-01-23T20:12:59.915278Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# model = AutoModelForSequenceClassification.from_pretrained(german_sentiment_path)\n# tokenizer = AutoTokenizer.from_pretrained(german_sentiment_path, use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:12:59.917429Z","iopub.execute_input":"2024-01-23T20:12:59.917764Z","iopub.status.idle":"2024-01-23T20:12:59.922133Z","shell.execute_reply.started":"2024-01-23T20:12:59.917734Z","shell.execute_reply":"2024-01-23T20:12:59.921296Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(xlm_t_path)\ntokenizer = AutoTokenizer.from_pretrained(xlm_t_path, use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:12:59.923483Z","iopub.execute_input":"2024-01-23T20:12:59.923784Z","iopub.status.idle":"2024-01-23T20:13:10.668399Z","shell.execute_reply.started":"2024-01-23T20:12:59.923761Z","shell.execute_reply":"2024-01-23T20:13:10.667262Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b0a8b73d70e481ea33300dcdf66b0af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b3ee3275684ab89fde1f8385a80852"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2848620fc2684eddbe2c9a0eb1581cb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34a5579d33c741e5b22ee431701c6300"}},"metadata":{}}]},{"cell_type":"code","source":"test_classification_report(model, test_text_noscare, test_labels_noscare)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T20:13:10.672124Z","iopub.execute_input":"2024-01-23T20:13:10.672594Z","iopub.status.idle":"2024-01-23T21:57:10.518931Z","shell.execute_reply.started":"2024-01-23T20:13:10.672567Z","shell.execute_reply":"2024-01-23T21:57:10.517942Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    Negative       0.68      0.86      0.76    238676\n     Neutral       0.29      0.77      0.42     41398\n    Positive       0.97      0.75      0.84    579501\n\n    accuracy                           0.78    859575\n   macro avg       0.65      0.79      0.68    859575\nweighted avg       0.85      0.78      0.80    859575\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}